# Clara â€“ Privacy-First GenAI WebUI for Open Source Models

[![TypeScript](https://img.shields.io/badge/TypeScript-5.5.3-blue.svg)](https://www.typescriptlang.org/)
[![React](https://img.shields.io/badge/React-18.3.1-blue.svg)](https://reactjs.org/)
[![Vite](https://img.shields.io/badge/Vite-5.4.2-646CFF.svg)](https://vitejs.dev/)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-3.4.1-38B2AC.svg)](https://tailwindcss.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Clara is a privacy-focused, fully client-side AI assistant that provides a secure, intuitive interface for interacting with AI models via Ollama. Unlike cloud-based solutions like OpenAI or Gemini, **Clara doesn't have any backend servers and never sends your data anywhere**. Your conversations and data remain entirely yours, securely stored in your browser.

## ğŸ”’ Privacy First
- **Local-only data storage**: No backend, no data leaks.
- **Direct Ollama integration**: Simply provide your local Ollama URL, and you're ready.

## âœ¨ Current Features
- ğŸ’¬ Real-time, secure chat with streaming responses
- ğŸŒ“ Automatic light/dark mode
- ğŸ“ Markdown rendering with syntax highlighting
- ğŸ“š Persistent chat history (stored locally)
- ğŸ” Easy model selection and configuration

## ğŸš§ Upcoming Features
- ğŸ–¼ï¸ Image generation
- ğŸ“± Mobile-responsive design
- ğŸ“ File attachments
- ğŸ¤ Voice input/output
- ğŸ”Œ Custom apps & plugin system

## ğŸš€ Quick Start

### Prerequisites
- **Node.js** v20+
- **Ollama** installed locally ([install instructions](https://ollama.ai/))

### Installation
```bash
git clone https://github.com/yourusername/clara-ai.git
cd clara-ai
npm install
npm run dev
```

### Setup Ollama

Start Ollama server and pull models:
```bash
ollama serve

# Example model
ollama pull mistral
```

Configure CORS for web access:
```bash
sudo systemctl edit ollama.service

# Add this to enable web access
[Service]
Environment="OLLAMA_ORIGINS=*"

sudo systemctl daemon-reload
sudo systemctl restart ollama
```

## ğŸ”— Remote Access with ngrok (optional)
Securely access your Ollama remotely via ngrok:

```bash
npm install -g ngrok
ngrok http 11434
```
Then use the generated URL in Clara's settings.

## ğŸ—ï¸ Project Structure
```
clara/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/     # UI components
â”‚   â”œâ”€â”€ hooks/          # Custom hooks
â”‚   â”œâ”€â”€ utils/          # Helper functions
â”‚   â”œâ”€â”€ db/             # Local storage (IndexedDB)
â”‚   â””â”€â”€ App.tsx         # Application entry
â”œâ”€â”€ public/             # Static assets
â””â”€â”€ package.json        # Dependencies
```

## ğŸš¢ Deployment
Deploy the `dist` directory to any static host (e.g., Netlify, GitHub Pages).

## ğŸ¤ Contribute
1. Fork repository
2. Create feature branch (`git checkout -b feature/YourFeature`)
3. Commit changes (`git commit -m 'Add YourFeature'`)
4. Push branch (`git push origin feature/YourFeature`)
5. Submit Pull Request

## ğŸ“„ License
MIT License â€“ [LICENSE](LICENSE)

---

ğŸŒŸ **Built with privacy and security at its core.** ğŸŒŸ