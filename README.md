# Clara - AI Assistant ğŸ¤–

[![Netlify Status](https://api.netlify.com/api/v1/badges/f0c8f7-lustrous-stroopwafel/deploy-status)](https://lustrous-stroopwafel-f0c8f7.netlify.app)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.5.3-blue.svg)](https://www.typescriptlang.org/)
[![React](https://img.shields.io/badge/React-18.3.1-blue.svg)](https://reactjs.org/)
[![Vite](https://img.shields.io/badge/Vite-5.4.2-646CFF.svg)](https://vitejs.dev/)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-3.4.1-38B2AC.svg)](https://tailwindcss.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Clara is a modern, feature-rich AI assistant web application that provides a seamless interface for interacting with various AI models through Ollama. Built with React, TypeScript, and Tailwind CSS, it offers a beautiful and intuitive chat experience with support for both text and image inputs.

![Clara AI Assistant](https://source.unsplash.com/random/1200x630/?ai,technology)

## âœ¨ Features

### Core Features
- ğŸ’¬ Real-time chat interface with streaming responses
- ğŸ–¼ï¸ Image processing capabilities with compatible models
- ğŸ“ Markdown support with syntax highlighting
- ğŸŒ“ Light/Dark mode with system preference sync
- ğŸ“Š Usage statistics and analytics
- ğŸ” Advanced model selection and configuration
- ğŸ’¾ Persistent storage with chat history
- ğŸ¯ Context-aware conversations

### Chat Management
- ğŸ”– Star important conversations
- ğŸ“ Archive old chats
- ğŸ—‘ï¸ Soft delete with recovery option
- ğŸ“ File attachment support (coming soon)
- ğŸ¤ Voice input support (coming soon)

### Developer Features
- ğŸ› ï¸ Debug console for API testing
- ğŸ“‹ Code block copying
- ğŸ”§ Comprehensive model configuration
- ğŸ“ˆ Response time monitoring
- ğŸ” Detailed error reporting

## ğŸš€ Getting Started

### Prerequisites

1. **Node.js**: Version 20 or higher
2. **Ollama**: Local installation required
   ```bash
   # macOS/Linux
   curl https://ollama.ai/install.sh | sh
   
   # Windows
   # Download from https://ollama.ai/download
   ```

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/clara-ai.git
   cd clara-ai
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Start the development server:
   ```bash
   npm run dev
   ```

### Ollama Setup

1. Start Ollama server:
   ```bash
   ollama serve
   ```

2. Pull required models:
   ```bash
   # For text-only support
   ollama pull mistral
   
   # For image support
   ollama pull llava
   ```

3. Configure CORS for web access:

   Create or modify the Ollama service configuration:
   ```bash
   sudo systemctl edit ollama.service
   ```

   Add the following:
   ```ini
   [Service]
   Environment="OLLAMA_ORIGINS=*"
   ```

   Restart Ollama:
   ```bash
   sudo systemctl daemon-reload
   sudo systemctl restart ollama
   ```

### Using ngrok for Remote Access

If you're running Ollama on a different machine or need remote access, you can use ngrok to create a secure tunnel:

1. Install ngrok:
   ```bash
   # Using npm
   npm install -g ngrok
   
   # Or download from https://ngrok.com/download
   ```

2. Start ngrok tunnel:
   ```bash
   ngrok http 11434
   ```

3. Use the provided ngrok URL in Clara's settings:
   ```
   https://your-ngrok-url.ngrok.io
   ```

> âš ï¸ **Important**: The ngrok URL changes each time you restart ngrok unless you have a paid account. For persistent access, consider:
> - Using a static domain with proper CORS configuration
> - Setting up a reverse proxy with nginx
> - Using ngrok with a paid account for static URLs

## ğŸ—ï¸ Project Structure

```
clara/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/           # React components
â”‚   â”‚   â”œâ”€â”€ assistant_components/  # Chat-specific components
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ hooks/               # Custom React hooks
â”‚   â”œâ”€â”€ utils/               # Utility functions
â”‚   â”œâ”€â”€ db/                  # Database layer
â”‚   â””â”€â”€ App.tsx             # Main application
â”œâ”€â”€ public/                  # Static assets
â””â”€â”€ package.json            # Project configuration
```

## ğŸ”„ Development Workflow

1. Make changes to the code
2. Test using the Debug console
3. Build the project:
   ```bash
   npm run build
   ```
4. Preview the production build:
   ```bash
   npm run preview
   ```

## ğŸš¢ Deployment

The project is configured for deployment on Netlify with automatic builds and deployments.

### Manual Deployment

1. Build the project:
   ```bash
   npm run build
   ```

2. Deploy the `dist` folder to any static hosting service

### Environment Variables

No environment variables are required for the frontend as all configuration is handled through the UI.

## ğŸ›£ï¸ Roadmap

### Coming Soon
- ğŸ“± Mobile-responsive design
- ğŸ¤ Voice input/output
- ğŸ“ File attachment support
- ğŸ” Authentication system
- ğŸ”„ Conversation branching
- ğŸ“Š Advanced analytics

### Future Updates
- ğŸŒ Multi-model conversations
- ğŸ¤ Collaborative features
- ğŸ”Œ Plugin system
- ğŸ—£ï¸ Multi-language support
- ğŸ“± Progressive Web App (PWA)

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) for the amazing AI model serving platform